"""Generation of ROIs from signal from fiducial beads

Fiducial beads are small points of flurescence which should be positioned identically 
in each of the images within a field of view, throughout the time course of the imaging 
experiment. As such, they can be used to align images to correct for drift.

These are generated by adding a small quantity of diluted solution that will produce 
small points of fluorescence at an expected wavelength when excited at a particular 
intensity. In a particular imaging channel, we then detect these points of light 
and generate regions of interest (ROIs) corresponding to them.
"""

__author__ = "Vince Reuter"

import dataclasses
from joblib import Parallel, delayed
from pathlib import Path
from typing import *

from gertils import ExtantFolder
import numpy as np
import pandas as pd
import scipy.ndimage as ndi
from skimage.measure import regionprops_table

from looptrace.numeric_types import NumberLike

PathLike = Union[str, Path]
ImageArrayLike = Union["FiveTensor", List["FourTensor"]]


class ArrayDimensionalityError(Exception):
    """Error subtype to represent an error in array dimensionality"""


def validate_array_dimension(arr: np.ndarray, expected: int) -> None:
    obs = len(arr.shape)
    if obs != expected:
        raise ArrayDimensionalityError(f"Expected {expected} dimensions, but got {obs}")


@dataclasses.dataclass
class FourTensor:
    data: np.ndarray

    def __post_init__(self) -> None:
        validate_array_dimension(arr=self.data, expected=4)

@dataclasses.dataclass
class FiveTensor:
    data: np.ndarray

    def __post_init__(self) -> None:
        validate_array_dimension(arr=self.data, expected=4)


def iterate_over_pos_time_images(image_array: ImageArrayLike) -> Iterable[Tuple[int, FourTensor]]:
    if isinstance(image_array, FiveTensor):
        def gen_pos_images():
            for i in range(image_array.shape[0]):
                yield i, image_array[i, :, :, :, :]
    elif isinstance(image_array, list) and all(isinstance(arr, FourTensor) for arr in image_array):
        gen_pos_images = lambda _: enumerate(image_array)
    elif isinstance(image_array, np.ndarray):
        raise ArrayDimensionalityError(f"Illegal shape for positional iteration over image array: {image_array.shape}")
    else:
        raise TypeError(f"Illegal image array for positional iteration: {type(image_array).__name__}")
    for p, pos_imgs in gen_pos_images():
        for t in range(pos_imgs.shape[0]):
            yield (p, t), pos_imgs[t, :, :, :]


def generate_all_bead_rois(image_array: ImageArrayLike, output_folder: ExtantFolder, params: "BeadRoiParameters", **joblib_kwargs) -> List[Tuple[Path, pd.DataFrame]]:
    def get_outfile(pos_idx: int, frame_idx: int) -> Path:
        return output_folder.path / f"bead_rois__{pos_idx}_{frame_idx}.csv"
    def proc1(img: np.ndarray, outfile: Path) -> Tuple[Path, pd.DataFrame]:
        rois = params.compute_labeled_regions(img=img)
        rois.to_csv(outfile)
        return outfile, rois
    return Parallel(**joblib_kwargs)(delayed(proc1)(
        get_outfile(pos_idx=pos_idx, frame_idx=frame), img) 
        for (pos_idx, frame), img in iterate_over_pos_time_images(image_array=image_array)
        )


@dataclasses.dataclass
class BeadRoiParameters:
    min_intensity_for_segmentation: NumberLike
    min_intensity_for_detection: NumberLike
    roi_pixels: int
    max_region_size: NumberLike
    max_intensity_for_detection: Optional[NumberLike] = None

    def generate_image_rois(self, img: np.ndarray, num_points: int, filtered_filepath: Optional[PathLike] = None, unfiltered_filepath: Optional[PathLike] = None) -> np.ndarray[int]:
        """
        Parameters
        ----------
        img : np.ndarray
            3D array in which each value is a pixel intensity
        num_points : int
            How many bead ROIs to return
        filtered_filepath : str or Path, optional
            Path to which to write the ROIs chosen / sampled; 
            if unspecified, don't write anything
        unfiltered_filepath : str or Path, optional
            Path to which to write the ROIs before sampling, but with QC label based on detection criteria; 
            if unspecified, don't write anything

        Returns
        -------
        np.ndarray
            3 x num_points array of 3D bead coordinates in given image
        """
        
        img_maxima = self.compute_labeled_regions(img=img)

        if unfiltered_filepath:
            print(f"Writing unfiltered bead ROIs: {unfiltered_filepath}")
            unfiltered_filepath.parent.mkdir(parents=False, exist_ok=True)
            img_maxima.to_csv(unfiltered_filepath)

        print("Filtering bead ROIs")
        num_unfiltered = len(img_maxima)
        img_maxima = img_maxima[img_maxima["fail_code"] == ""]
        num_filtered = len(img_maxima)
        print(f"Bead ROIs remaining: {num_filtered}/{num_unfiltered}")

        # Sample the ROIs, or retain all of them, depending on the config setting for number of points, and 
        # the number of regions which satisfy the filtration criteria.
        if num_points == -1:
            print(f"Using all bead ROIs based on setting for number of points")
        elif num_filtered <= num_points:
            print(f"Using all bead ROIs based on number remaining: {num_filtered} <= {num_points}")
        else:
            print(f"Sampling bead ROIs: {num_points}/{num_filtered}")
            img_maxima = img_maxima.sample(n=num_points, random_state=1)
        
        if filtered_filepath:
            print(f"Writing sampled bead ROIs: {filtered_filepath}")
            img_maxima.to_csv(filtered_filepath)

        return np.round(img_maxima[["centroid-0", "centroid-1", "centroid-2"]].to_numpy()).astype(int)

    def compute_labeled_regions(self, img: np.ndarray) -> pd.DataFrame:
        """Find contiguous regions (according to instance settings) within given image, and assign fail code(s)."""
        # Segment the image into contiguous regions of signal above the current threshold.
        img_maxima = self._extract_regions(img)
        
        # Apply failure code labels based on the regional filtration criteria.
        img_maxima["fail_code"] = self._compute_discard_reasons(regions=img_maxima)

        return img_maxima

    def _extract_regions(self, img: np.ndarray) -> pd.DataFrame:
        # Segment the given image into regions of pixels in which the signal intensity exceeds the segmentation threshold.
        img_label, num_labels = self._segment_image(img)
        print("Number of unfiltered beads found: ", num_labels)
        # Extract the relevant data for each of the segmented regions.
        return pd.DataFrame(regionprops_table(img_label, img, properties=("label", "centroid", "max_intensity", "area")))

    def _compute_discard_reasons(self, regions: pd.DataFrame) -> pd.Series:
        # TODO: why divide-by-2 here?
        roi_px = self.roi_pixels // 2
        # TODO: record better the mapping from -0/-1/-2 to z/y/x.
        too_high = (lambda _: False) if self.max_intensity_for_detection is None \
            else (lambda row: row ["max_intensity"] > self.max_intensity_for_detection)
        invalidation_label_pairs = [
            (lambda row: row["centroid-0"] <= roi_px, "z"), 
            (lambda row: row["centroid-1"] <= roi_px, "y"), 
            (lambda row: row["centroid-2"] <= roi_px, "x"), 
            (lambda row: row["area"] > self.max_region_size, "s"), 
            (lambda row: row["max_intensity"] < self.min_intensity_for_detection, "i"), 
            (too_high, "I"), 
            ]
        return regions.apply(lambda row: "".join(code if fails(row) else "" for fails, code in invalidation_label_pairs), axis=1)

    def _segment_image(self, img: np.ndarray) -> Tuple[np.ndarray, int]:
        return ndi.label(img > self.min_intensity_for_segmentation)
